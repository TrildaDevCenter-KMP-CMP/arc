"use strict";(self.webpackChunkarc=self.webpackChunkarc||[]).push([[846],{1032:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var l=n(4848),a=n(8453);const o={title:"Ollama Client"},r=void 0,s={id:"clients/ollama",title:"Ollama Client",description:"The Ollama Client connects to the Completion API of a running Ollama server.",source:"@site/docs/02-clients/ollama.md",sourceDirName:"02-clients",slug:"/clients/ollama",permalink:"/docs/clients/ollama",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{title:"Ollama Client"},sidebar:"tutorialSidebar",previous:{title:"Google Gemini",permalink:"/docs/clients/gemini"},next:{title:"Readers",permalink:"/docs/readers/"}},i={},c=[];function m(e){const t={a:"a",code:"code",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(t.p,{children:"The Ollama Client connects to the Completion API of a running Ollama server."}),"\n",(0,l.jsx)(t.p,{children:"Ollama is a great way to run LLM models locally. Even without expensive hardware, smaller models,\nsuch as Gemma 7B, can be a great way to start experimenting with Arc Agents."}),"\n",(0,l.jsxs)(t.p,{children:["See ",(0,l.jsx)(t.a,{href:"https://ollama.com/",children:"https://ollama.com/"})," for more details."]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-kotlin",children:'val client = OllamaClient(OllamaClientConfig("modelName", "url"), eventPublisher)\n'})})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(m,{...e})}):m(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var l=n(6540);const a={},o=l.createContext(a);function r(e){const t=l.useContext(o);return l.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),l.createElement(o.Provider,{value:t},e.children)}}}]);